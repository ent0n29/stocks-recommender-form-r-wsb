{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WallStreetBets-Preprocessing.ipynb","provenance":[{"file_id":"108ofFsEzbswK2E1tzkPfr6UU6jPHRTx-","timestamp":1616988199266}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSmCrU8CYLkf","executionInfo":{"status":"ok","timestamp":1618630239506,"user_tz":240,"elapsed":62221,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"a602f6bc-6962-45ec-af31-4da2c35f35de"},"source":["!pip install pyspark\n","!pip install praw\n","!pip3 install iexfinance\n","!pip install pickle-mixin\n","!pip install pandas\n","!pip install requests-futures\n","!pip install holidays"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n","\u001b[K     |████████████████████████████████| 212.3MB 69kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 47.4MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=5aff5c392e3bd7447c4712363080fe30b8cecbaec259785ebd5cb7e29f516195\n","  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.1.1\n","Collecting praw\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/a8/a2e2d0750ee17c7e3d81e4695a0338ad0b3f231853b8c3fa339ff2d25c7c/praw-7.2.0-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 4.2MB/s \n","\u001b[?25hCollecting prawcore<3,>=2\n","  Downloading https://files.pythonhosted.org/packages/7d/df/4a9106bea0d26689c4b309da20c926a01440ddaf60c09a5ae22684ebd35f/prawcore-2.0.0-py3-none-any.whl\n","Collecting update-checker>=0.18\n","  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n","Collecting websocket-client>=0.54.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n","\u001b[K     |████████████████████████████████| 61kB 4.7MB/s \n","\u001b[?25hRequirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from prawcore<3,>=2->praw) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2->praw) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2->praw) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2->praw) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2->praw) (2.10)\n","Installing collected packages: prawcore, update-checker, websocket-client, praw\n","Successfully installed praw-7.2.0 prawcore-2.0.0 update-checker-0.18.0 websocket-client-0.58.0\n","Collecting iexfinance\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/a6/653eb3306789f97f761a7889913923e0e814967a342099d4f11c0604eaa1/iexfinance-0.5.0-py3-none-any.whl (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from iexfinance) (1.1.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from iexfinance) (2.23.0)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->iexfinance) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->iexfinance) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->iexfinance) (2018.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->iexfinance) (3.0.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->iexfinance) (1.15.0)\n","Installing collected packages: iexfinance\n","Successfully installed iexfinance-0.5.0\n","Collecting pickle-mixin\n","  Downloading https://files.pythonhosted.org/packages/02/77/9d5eb2201bbc130e2a5cc41fc949e4ab0da74b619107eac1c511be3af7a7/pickle-mixin-1.0.2.tar.gz\n","Building wheels for collected packages: pickle-mixin\n","  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-cp37-none-any.whl size=5999 sha256=de5e23e5fd215fb2d4e627946b9cc661ce40af5e0cf0b52f55773e46c248d870\n","  Stored in directory: /root/.cache/pip/wheels/cd/05/42/71de70fa36b9cbb7657bb5793a16f8028c1cdc1bdd3b8e1ac3\n","Successfully built pickle-mixin\n","Installing collected packages: pickle-mixin\n","Successfully installed pickle-mixin-1.0.2\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Collecting requests-futures\n","  Downloading https://files.pythonhosted.org/packages/47/c4/fd48d1ac5110a5457c71ac7cc4caa93da10a80b8de71112430e439bdee22/requests-futures-1.0.0.tar.gz\n","Requirement already satisfied: requests>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from requests-futures) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.2.0->requests-futures) (2.10)\n","Building wheels for collected packages: requests-futures\n","  Building wheel for requests-futures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for requests-futures: filename=requests_futures-1.0.0-cp37-none-any.whl size=7012 sha256=c5b5ab74e5a8a7d79f404d8008da9d64f88c885b631ad9502a1a194e08d5c1d8\n","  Stored in directory: /root/.cache/pip/wheels/26/d0/f5/dc4e4a37bbe55c9acf967d2bd899152412c1e49c227f5395ff\n","Successfully built requests-futures\n","Installing collected packages: requests-futures\n","Successfully installed requests-futures-1.0.0\n","Requirement already satisfied: holidays in /usr/local/lib/python3.7/dist-packages (0.10.5.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from holidays) (2.8.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays) (1.15.0)\n","Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays) (2.1.1)\n","Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays) (2.3.2)\n","Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays) (0.2.1)\n","Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays) (0.5.11)\n","Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays) (2018.9)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KV_t_JDlZHAg"},"source":["from pyspark.rdd import RDD\n","from pyspark.sql import Row\n","from pyspark.sql import DataFrame\n","from pyspark.sql import SparkSession\n","from pyspark import SparkContext as sc\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from iexfinance.stocks import Stock\n","from iexfinance.stocks import get_historical_data\n","import os\n","# tools\n","import re\n","import math\n","import json\n","import requests\n","import itertools\n","import numpy as np\n","import pandas as pd\n","import time\n","from datetime import date\n","from datetime import datetime, timedelta\n","import string\n","import holidays\n","\n","# input true for sandbox\n","def sandbox(change):\n","  if change:\n","    # Set IEX Finance API Token for Sandbox test mode\n","    os.environ['IEX_API_VERSION'] = 'iexcloud-sandbox'\n","    os.environ['IEX_TOKEN'] = 'Tsk_4060833567884b49870980c4a917aa92'\n","  else:\n","    # Real\n","    os.environ['IEX_API_VERSION'] = 'stable'\n","    os.environ['IEX_TOKEN'] = ''\n","\n","sandbox(True)\n","\n","def init_spark():\n","    spark = SparkSession \\\n","        .builder \\\n","        .appName(\"Python Spark SQL basic example\") \\\n","        .config(\"spark.some.config.option\", \"some-value\") \\\n","        .getOrCreate()\n","    return spark\n","spark = init_spark()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wK4nDaIo9KCf"},"source":["'''\n","Function to find the ticker of the stock talked about in a post.\n","'''\n","\n","# helper function for get_ticker, extracts ticker after dollar signs if exists\n","def check_after_dollarsign(body, start_index):\n","   \"\"\"\n","   Given a starting index and text, this will extract the ticker, return None if it is incorrectly formatted.\n","   \"\"\"\n","   count  = 0\n","   ticker = \"\"\n","\n","   for char in body[start_index:]:\n","      # if it should return\n","      if not char.isalpha():\n","         # if there aren't any letters following the $\n","         if (count == 0):\n","            return None\n","\n","         return ticker.upper()\n","      else:\n","         ticker += char\n","         count += 1\n","\n","   return ticker.upper()\n","\n","# function to retrieve ticker from a body of text\n","def get_ticker(body):\n","   # frequent words that look like tickers but aren't\n","   blacklist_words = [\n","      \"YOLO\", \"TOS\", \"CEO\", \"CFO\", \"CTO\", \"DD\", \"BTFD\", \"WSB\", \"OK\", \"RH\",\n","      \"KYS\", \"FD\", \"TYS\", \"US\", \"USA\", \"IT\", \"ATH\", \"RIP\", \"BMW\", \"GDP\",\n","      \"OTM\", \"ATM\", \"ITM\", \"IMO\", \"LOL\", \"DOJ\", \"BE\", \"PR\", \"PC\", \"ICE\",\n","      \"TYS\", \"ISIS\", \"PRAY\", \"PT\", \"FBI\", \"SEC\", \"GOD\", \"NOT\", \"POS\", \"COD\",\n","      \"AYYMD\", \"FOMO\", \"TL;DR\", \"EDIT\", \"STILL\", \"LGMA\", \"WTF\", \"RAW\", \"PM\",\n","      \"LMAO\", \"LMFAO\", \"ROFL\", \"EZ\", \"RED\", \"BEZOS\", \"TICK\", \"IS\", \"DOW\"\n","      \"AM\", \"PM\", \"LPT\", \"GOAT\", \"FL\", \"CA\", \"IL\", \"PDFUA\", \"MACD\", \"HQ\",\n","      \"OP\", \"DJIA\", \"PS\", \"AH\", \"TL\", \"DR\", \"JAN\", \"FEB\", \"JUL\", \"AUG\",\n","      \"SEP\", \"SEPT\", \"OCT\", \"NOV\", \"DEC\", \"FDA\", \"IV\", \"ER\", \"IPO\", \"RISE\"\n","      \"IPA\", \"URL\", \"MILF\", \"BUT\", \"SSN\", \"FIFA\", \"USD\", \"CPU\", \"AT\",\n","      \"GG\", \"ELON\", \"I\", \"WE\", \"A\"\n","   ]\n","\n","   # FIRST CHECK IF THERE'S A $TICKER WITH DOLLAR SIGN\n","   if '$' in body:\n","      index = body.find('$') + 1\n","      word = check_after_dollarsign(body, index)\n","      \n","      if word and word not in blacklist_words:\n","         try:\n","            # special case for $ROPE\n","            if word != \"ROPE\":\n","               # sends request to IEX API to determine whether the current word is a valid ticker\n","               # if it isn't, it'll return an error and therefore continue on to the next word\n","               price = Stock(word).get_company()\n","               return word\n","         except Exception as e:\n","            pass\n","   \n","   # IF NO TICKER WITH DOLLAR SIGN, CHECK FOR TICKER WITHOUT IT: splits every body into list of words\n","   word_list = re.sub(\"[^\\w]\", \" \",  body).split()\n","   for count, word in enumerate(word_list):\n","      # initial screening of words\n","      if word.isupper() and len(word) >= 1 and (word.upper() not in blacklist_words) and len(word) <= 5 and word.isalpha():\n","         try:\n","            # special case for $ROPE\n","            if word != \"ROPE\":\n","               price = Stock(word).get_company()\n","               return word\n","         except Exception as e: \n","            continue\n","      \n","   # if no ticker was found\n","   return \"None\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pt_uZ0yx9jm1","executionInfo":{"status":"ok","timestamp":1618630248484,"user_tz":240,"elapsed":71172,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"2b3831cf-462d-4bee-bd95-3ee917f3b9d8"},"source":["'''\n","Test IEXFinance API ticker extraction\n","'''\n","text = \"I'm going to buy some AAPL yeee.\"\n","ticker = get_ticker(text)\n","# Individual stock test\n","#hi = Stock(\"asdlkjf\").get_company()\n","print(\"Getting random ticker: \", ticker)\n","#quote = Stock(\"AAPL\")\n","# get's stock price\n","#one_price = quote.get_quote().latestPrice[ticker]\n","#print(\"one price: \", one_price)\n","now = datetime.now().timestamp()\n","end = datetime.fromtimestamp(1617658992)\n","start = datetime.fromtimestamp(1617658992 - 86400)\n","# gets the closing prices from a week ago till today. use the latest price!\n","price = get_historical_data(\"AAPL\", start, end, close_only=True)\n","print(price.close)\n","# # get last price!\n","print(price.close[-1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Getting random ticker:  AAPL\n","2021-04-05    131.5\n","Name: close, dtype: object\n","131.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hQ1VC_zARJ62"},"source":["'''\n","- return false if date is holiday or weekend (market close), else return date\n","'''\n","def get_start_date(created):\n","  # 1 day before post date\n","  us_holidays = holidays.UnitedStates(years = 2021)\n","  ticker_date = datetime.fromtimestamp(int(created) - 86400).date()\n","  \n","  # if not holiday or good friday or weekend\n","  if ticker_date in us_holidays or ticker_date == datetime(2021, 4, 2).date():\n","    return False\n","  if ticker_date.weekday() in [5,6]:\n","    return False\n","  \n","  return ticker_date"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8mY1Y3M8ZE3S","executionInfo":{"status":"ok","timestamp":1618630248487,"user_tz":240,"elapsed":71155,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"34a02551-04f7-4ae0-9055-e8bb90bbc0b1"},"source":["# Testing\n","newyear = 1609609392\n","get_start_date(newyear)\n","\n","ticker_date = datetime.fromtimestamp(int(1617658992)- 86400 - 86400 - 86400).date()\n","print(ticker_date == datetime(2021, 4, 2).date())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"olDQK62m1WE9"},"source":["'''\n","Compute growth % of associated stock in a given post.\n","'''\n","# computes growth % of given DD\n","# (today's price <> price at DD's date) = percentage growth from then to now of the stock\n","def growth1(ticker, created):\n","    if not ticker or ticker == \"None\":\n","        return \"N/A\"\n","    # get today's date and DD's date (ranges from <>1 week in case of weekends/holidays)\n","    try:\n","        # get today's price\n","        price_today = Stock(ticker).get_quote().latestPrice[ticker]\n","\n","        ticker_date_start = get_start_date(created)\n","        ticker_date_end = datetime.fromtimestamp(int(created))\n","\n","        # dates for post creation: loop until get valid date\n","        counter = 0\n","        new_date = created\n","        while not ticker_date_start and counter < 20:\n","          counter += 1\n","          new_date -= 86400\n","          ticker_date_start = get_start_date(new_date)\n","        # get DD date's price\n","        if ticker_date_start:\n","          ticker_date_end = ticker_date_start + timedelta(days=0.8)\n","          price_ticker_date = get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True).close[0]\n","\n","        # compute percentage growth\n","        percentage = ((price_today / price_ticker_date) - 1) * 100\n","        return \"{:.2f}\".format(percentage) + \"%\"\n","    except Exception as e:\n","        return \"N/A\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Msq6kRNLLnk0"},"source":["'''\n","Compute growth % of associated stock in a given post.\n","'''\n","# computes growth % of given DD\n","# (today's price <> price at DD's date) = percentage growth from then to now of the stock\n","def growth(ticker, created):\n","    if not ticker or ticker == \"None\":\n","        return \"N/A\"\n","    # get today's date and DD's date (ranges from <>1 week in case of weekends/holidays)\n","    try:\n","        # get today's price\n","        price_today = Stock(ticker).get_quote().latestPrice[ticker]\n","        print(\"ok\",price_today)\n","\n","        ticker_date_start = get_start_date(created)\n","        ticker_date_end = datetime.fromtimestamp(int(created))\n","\n","        # dates for post creation: loop until get valid date\n","        counter = 0\n","        new_date = created\n","        while not ticker_date_start and counter < 20:\n","          counter += 1\n","          new_date -= 86400\n","          ticker_date_start = get_start_date(new_date)\n","        # get DD date's price\n","        if ticker_date_start:\n","          # sandbox(True)\n","          # test = get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True).close[0]\n","          # sandbox(False)\n","          ticker_date_end = ticker_date_start + timedelta(days=0.8)\n","          test = get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True)\n","          print(\"test\", test)\n","          price_ticker_date = test.close[0]\n","\n","        print(ticker_date_start, ticker_date_end)\n","        # compute percentage growth\n","        percentage = ((price_today / price_ticker_date) - 1) * 100\n","        return \"{:.2f}\".format(percentage) + \"%\"\n","    except Exception as e:\n","        print(e)\n","        return \"N/A\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":97},"id":"SQlBbmteP7o7","executionInfo":{"status":"ok","timestamp":1618630249299,"user_tz":240,"elapsed":71943,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"8a0d2153-3fa1-420b-e8d5-76d747e3022f"},"source":["'''\n","Test growth function\n","'''\n","# 1/11/2021 -> dont work\n","#date = 1610473392\n","date = 1617656836\n","ticker = \"GME\"\n","ticker_date_start = datetime.fromtimestamp(int(date))\n","ticker_date_end = ticker_date_start + timedelta(days=1)\n","print(ticker_date_start, ticker_date_end)\n","get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-05 21:07:16 2021-04-06 21:07:16\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>close</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-04-06</th>\n","      <td>190</td>\n","      <td>6344521</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           close   volume\n","2021-04-06   190  6344521"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"zBk3suhmCqFA"},"source":["'''\n","Data cleaning step\n","- Remove all punctuation, numbers, new lines, tabs, consecutive spaces in text.\n","'''\n","def clean_text(text):\n","  # remove punctuation except $\n","  cleaned = text.translate(str.maketrans(' ', ' ', string.punctuation.replace('$','') + '’')).lower()\n","  # remove links (http)\n","  cleaned = re.sub(\"http\\w+\", \" \", cleaned)\n","  # remove digits\n","  cleaned = cleaned.translate({ord(k): None for k in string.digits})\n","  # remove tabs/newlines\n","  cleaned = cleaned.replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip()\n","  # remove double space\n","  cleaned = re.sub(' +', ' ', cleaned)\n","  return cleaned"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120},"id":"jDq9c0B9Cy0C","executionInfo":{"status":"ok","timestamp":1618630249304,"user_tz":240,"elapsed":71916,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"4c4e2b0f-66c5-4763-d5ee-f545966f9fba"},"source":["'''\n","Testing clean_text()\n","'''\n","dirty = \" Hi I'm Pan. We a213re http://kek.com g5.3oin2g 5.4 to 3 havhttp://kek.come a VERY\\n  [GOOD GRADE] in \\tthis class: \\nnot even  # kidding, @our project is 2 good... Soyeah!!! If you ask me 'how?' i'll tell u we got 100%.\"\n","print(dirty)\n","print()\n","clean_text(dirty)"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" Hi I'm Pan. We a213re http://kek.com g5.3oin2g 5.4 to 3 havhttp://kek.come a VERY\n","  [GOOD GRADE] in \tthis class: \n","not even  # kidding, @our project is 2 good... Soyeah!!! If you ask me 'how?' i'll tell u we got 100%.\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'hi im pan we are going to hav a very good grade in this class not even kidding our project is good soyeah if you ask me how ill tell u we got'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"k554ETe-Iwf5"},"source":["'''\n","Data Filtering: validate post before adding.\n","'''\n","\n","def validate_post(post):\n","  return (post['link_flair_text']\n","    and post['upvote_ratio'] > 0.5\n","    and post['link_flair_css_class']\n","    and post['selftext']\n","    and not post['selftext'].isspace()\n","    and post['selftext'] != \"removed\"\n","    and post['selftext'] != \"[deleted]\"\n","    and post['score'] >= 5)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZrOYRS9T3hNS"},"source":["\"\"\"\n","Wrapper of requests\n","- uri: uri that we are making request from\n","- max_retry: maximum number of trial before timeout\n","\"\"\"\n","sesh = requests.session()\n","def get_request(uri, max_retry = 5):\n","  def get(uri):\n","    global get_attempts\n","    global sesh\n","    get_attempts += 1\n","    response = sesh.get(uri, timeout=20)\n","    assert response.status_code == 200\n","    return json.loads(response.content)\n","  # Retry if request call failed\n","  retry = 1\n","  while retry < max_retry:\n","    try:\n","      response = get(uri)\n","      return response\n","    except Exception as e:\n","      if 'timed out' in str(e):\n","        print(\"Retry \" + str(retry)+ \" Timed out. Request #\" + str(get_attempts))\n","      retry += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FQkcQb6TnlR_"},"source":["\"\"\"\n","Gets the all the posts from a given subreddit in the specific time range.\n","- subreddit: name of subreddit\n","- begin: timestamp (in unix) of start date\n","- end: timestamp (in unix) of end date\n","- returns: list of all the posts in the time interval as objects. {id=\"..\", title=\"...\", etc...}\n","\"\"\"\n","def get_posts(subreddit, begin, end):\n","  # Max size of each Pushshift API request is 100 posts.\n","  SIZE = 100\n","  #'https://api.pushshift.io/reddit/search/submission?subreddit=wallstreetbets&score=>5&size=25&selftext:not=\"preview.redd.it\"&fields=id,created_utc,title,score,upvote_ratio,author,link_flair_text,link_flair_css_class,num_comments,selftext,url'\n","  PUSHSHIFT_URI = r'https://api.pushshift.io/reddit/search/submission?subreddit={}&after={}&before={}&size={}&is_video=false&fields=total_awards_received,id,created_utc,title,score,upvote_ratio,author,link_flair_text,link_flair_css_class,num_comments,selftext,url'\n","  nb_requests_made = 1\n","  # filter the posts data\n","  def filter_posts(uri, begin, end):\n","    full_posts = get_request(uri.format(subreddit, begin, end, SIZE))\n","    if full_posts is None:\n","      raise ValueError(\"Response is empty or none.\")\n","    posts = []\n","    if full_posts!=None:\n","      for post in full_posts['data']:\n","        try:\n","          if validate_post(post):\n","            sandbox(True)\n","            ticker =  get_ticker(post['title'])\n","            posts.append({\\\n","              'id': post['id'],\\\n","              'ticker': ticker, \\\n","              'growth': growth(ticker, post['created_utc']),\\\n","              'title': clean_text(post['title']),\\\n","              'score': post['score'],\\\n","              'upvote_ratio': post['upvote_ratio'],\\\n","              'author': post['author'],\\\n","              'created_utc': post['created_utc'],\\\n","              'flair': post['link_flair_text'],\\\n","              'flaircss': post['link_flair_css_class'],\\\n","              'num_comments': post['num_comments'],\\\n","              'text': clean_text(post['selftext']),\\\n","              'total_awards': post['total_awards_received'],\\\n","              'url': post['url']\\\n","            })\n","        except:\n","          pass\n","      # get timestamp of last post\n","      #print(full_posts['data'][0][\"score\"])\n","      last_timestamp = full_posts['data'][-1]['created_utc']\n","      posts_amount = len(full_posts['data'])\n","          \n","      #return list(filtered)\n","      return [posts, last_timestamp, posts_amount]\n","    else:\n","      return None \n","  posts_etc = filter_posts(PUSHSHIFT_URI, begin, end)\n","  posts = posts_etc[0]\n","  last_timestamp = posts_etc[1]\n","  posts_amount = posts_etc[2]\n","\n","  # If reached limit of 100 posts retrieved, make request again until 'end' time.\n","  while posts_amount == SIZE:\n","    \n","    # Timestamp of the last post we previously retrieved\n","    new_begin = last_timestamp - 10\n","    more_posts_etc = filter_posts(PUSHSHIFT_URI, new_begin, end)\n","    if more_posts_etc==None:\n","      time.sleep(1)\n","      last_timestamp+=10\n","      print(\"sleep\")\n","    else:\n","      last_timestamp = more_posts_etc[1]\n","      posts_amount = more_posts_etc[2]\n","      posts.extend(more_posts_etc[0])\n","      nb_requests_made += 1\n","      print(new_begin,end)\n","    \n","  print(\"Number of requests made: \", nb_requests_made)\n","  return posts"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pv07kukZgPq5","executionInfo":{"status":"ok","timestamp":1618630249315,"user_tz":240,"elapsed":71903,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"cc186ce6-4dfb-43f9-8737-dc4ca3f51eec"},"source":["datetime.fromtimestamp(1612264874) - timedelta(days=8)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["datetime.datetime(2021, 1, 25, 11, 21, 14)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HPfvW-hwvTFh","executionInfo":{"status":"ok","timestamp":1618630831223,"user_tz":240,"elapsed":95418,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"b4407b62-e516-440e-e594-6c54d6151a25"},"source":["\"\"\"\n","Retrieve posts\n","- nb_days_from_today: number of days from 4 days ago you want to retrieve\n","- return: lists of all posts in time interval\n","\"\"\"\n","get_attempts = 0\n","def retrieve(nb_days_from_today):\n","  global get_attempts\n","  end = math.ceil(datetime.utcnow().timestamp() - 345600)\n","  if nb_days_from_today < 3650:\n","    begin = math.ceil((datetime.fromtimestamp(end) - timedelta(days=nb_days_from_today)).timestamp())\n","  else:\n","    begin = nb_days_from_today\n","  print(\"Timestamps: \", begin, end)\n","  posts = get_posts('wallstreetbets', begin, end)\n","\n","  unique_posts = np.unique([post['id'] for post in posts])\n","  print(\"Size: \", len(posts))\n","  print(\"Size of uniques: \", len(unique_posts))\n","  print(\"Example posts: \", posts[:5])\n","  print(\"Total requests: \" + str(get_attempts))\n","  return posts\n","\n","# all posts!\n","#70 days\n","posts = retrieve(5)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Timestamps:  1617853136 1618285136\n","1617862389 1618285136\n","1617876284 1618285136\n","1617882832 1618285136\n","1617886525 1618285136\n","1617890494 1618285136\n","1617893709 1618285136\n","1617896389 1618285136\n","1617899101 1618285136\n","1617902280 1618285136\n","1617904890 1618285136\n","1617908046 1618285136\n","1617910504 1618285136\n","1617913642 1618285136\n","1617916866 1618285136\n","1617919604 1618285136\n","1617923295 1618285136\n","1617927085 1618285136\n","1617931270 1618285136\n","1617936401 1618285136\n","1617942626 1618285136\n","1617950930 1618285136\n","1617961191 1618285136\n","1617968957 1618285136\n","1617975322 1618285136\n","1617977803 1618285136\n","1617980504 1618285136\n","1617983176 1618285136\n","1617986044 1618285136\n","1617989435 1618285136\n","1617992036 1618285136\n","1617994899 1618285136\n","1617998431 1618285136\n","1618000530 1618285136\n","Number of requests made:  34\n","Size:  0\n","Size of uniques:  0\n","Example posts:  []\n","Total requests: 36\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tvbLzAGHuHoT"},"source":["\"\"\"\n","Output to CSV\n","\n","using RDD and DF\n","\"\"\"\n","# convert unix timestamp to date e.g.: '2021-04-04'\n","def convert_to_date(timestamp):\n","  return str(datetime.fromtimestamp(int(timestamp)).date())\n","\n","posts_rdd = spark.sparkContext.parallelize(posts)\n","posts_rdd = posts_rdd.map(lambda post: Row(id=post['id'], ticker=post['ticker'], growth=post['growth'], title=post['title'], flair=str(post['flair']), score=post['score'], upvote_ratio=post['upvote_ratio'], author=str(post['author']), num_comments=post['num_comments'], text=post['text'].lower(), created=convert_to_date(post['created_utc']), url=post['url']))\n","# eliminate duplicates\n","posts_rdd = posts_rdd.distinct()\n","# serialize rdd, maybe better as pandas\n","#posts_rdd.saveAsPickleFile(\"pickled_WSBposts_rdd-test\")\n","\n","# convert to DF\n","posts_df = spark.createDataFrame(posts_rdd)\n","print(posts_df.count())\n","panda_posts = posts_df.toPandas()\n","\n","# write to csv\n","posts_df.coalesce(1).write.csv('fullflairs-60daysredditposts.csv', header=True)\n","panda_posts"],"execution_count":null,"outputs":[]}]}