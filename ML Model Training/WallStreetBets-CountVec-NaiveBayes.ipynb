{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WallStreetBets-CountVec-NaiveBayes.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RAJBJ8_Zg7eo"},"source":["# **WallStreetBets DD Recommender**\n","## Notebook for Naive Bayes classifier with CountVectorizer."]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"tCK3YmBuXKSV","outputId":"ca9b4516-c7ca-4b43-d3b0-1989d0dd001e"},"source":["#Installing all packages\n","!pip install numpy\n","!pip install matplotlib\n","!pip install scikit-learn\n","!pip install pyspark"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n","\u001b[K     |████████████████████████████████| 212.3MB 68kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 39.9MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=25dfc14800e4a1c2764ec88677cddd257b921a676ea5cf4def1e0a3170702a2f\n","  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.1.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tkQZFUUgZz7n"},"source":["### Importing libraries for data processing"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"A8nXPXUBYJK4"},"source":["from pyspark.rdd import RDD\n","from pyspark.sql import Row\n","from pyspark.sql import DataFrame\n","from pyspark.sql import SparkSession\n","from pyspark import SparkContext as sc\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from pyspark.sql.functions import udf,col\n","from pyspark.sql.types import ArrayType\n","from pyspark.sql.types import StringType\n","from pyspark.sql.types import IntegerType\n","\n","# tools\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z3PafnvLaRVm"},"source":["### Importing libraries for Machine learning models"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"BpfULFl8ZF95"},"source":["from pyspark.ml.classification import NaiveBayes\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.feature import CountVectorizer\n","from pyspark.ml.feature import StopWordsRemover\n","from pyspark.ml.clustering import KMeans\n","from pyspark.ml.evaluation import ClusteringEvaluator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"mSdK4WiaZJoO"},"source":["\"\"\"\n","Initialize Spark session object\n","\"\"\"\n","def init_spark():\n","    spark = SparkSession \\\n","        .builder \\\n","        .appName(\"Python Spark Naive Bayes CountVectorizer\") \\\n","        .getOrCreate()\n","    return spark\n","spark = init_spark()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v4_jjgQ_b9d6"},"source":["### Data preprocessing: Remove stop words and feature extraction"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jrMOC8X5Zk5p","executionInfo":{"status":"ok","timestamp":1618622990691,"user_tz":240,"elapsed":539,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"fd0ed345-7116-4344-84cb-30a96bebf4d3"},"source":["#Read lemmatized dataset created by WallStreetBets-CreateLemmas.ipynb \n","data = spark.read.csv(\"lemma.csv\", header=True)\n","\n","#id,label,lemmas\n","#ks1tzw,1,all|right|artist|.....\n","function_array = udf(lambda r: r.split(\"|\"), ArrayType(StringType()))\n","function_toNumerical = udf(lambda r: int(r), IntegerType())\n","text_lemmas = data.withColumn('finished_lemmas', function_array('text')).drop('text').withColumn('label', function_toNumerical('label'))\n","print(\"Number of rows: \",text_lemmas.count())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of rows:  1144\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n_L9lrQrolKo"},"source":["'''\n","Get the Corpus.\n","Removing stop words from the text lemmas. \n","'''\n","remover = StopWordsRemover(inputCol=\"finished_lemmas\", outputCol=\"text\")\n","filtered_df = remover.transform(text_lemmas)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROSiqgkmwGGu","executionInfo":{"status":"ok","timestamp":1618623078294,"user_tz":240,"elapsed":1603,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"61464b0d-b28c-434e-a5b1-47a8ae46d168"},"source":["'''\n","Create Document-Term Matrix by vectorizing the filtered text.\n","- returns the features column: \n","(total nb of words, indices of each word in total vocab, count of each word)\n","'''\n","to_vectorize = filtered_df.select('id', 'label', 'text')\n","cv = CountVectorizer(inputCol=\"text\", outputCol=\"features\")\n","model_vec = cv.fit(to_vectorize)\n","result_vec = model_vec.transform(to_vectorize)\n","print(\"Total count of vocabulary:\", len(model_vec.vocabulary))\n","selectedData = result_vec.select('id', 'label','features', 'text')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total count of vocabulary: 10933\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G0uIw5gmd22-"},"source":["### Building Naive Bayes classifier"]},{"cell_type":"code","metadata":{"id":"Mg1XXG03aAX3"},"source":["\"\"\"\n","Define TruePositive, FalsePositive and FalseNegative\n","x = prediction, y = label\n","\"\"\"\n","TP = udf(lambda x,y: int(x==1 and y==1))\n","FP = udf(lambda x,y: int(x==1 and y==0))\n","FN = udf(lambda x,y: int(x==0 and y==1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3W5XF4LSJM6"},"source":["'''\n","Naive-Bayes following from CountVectorizer\n","'''\n","def NAIVEBAYES_CV(smooth=1, model_type=\"multinomial\"): \n","  # separating train/test data\n","  training_zero, test_zero = selectedData.where(selectedData.label == 0).randomSplit([0.7, 0.3])\n","  training_one, test_one = selectedData.where(selectedData.label == 1).randomSplit([0.7, 0.3])\n","\n","  training = training_zero.union(training_one)\n","  test = test_zero.union(test_one)\n","\n","  # create trainer with parameters then train\n","  # smoothing: smooth probabilities of 0 to the input\n","  nb = NaiveBayes(smoothing=smooth, modelType=model_type)\n","  model_NB = nb.fit(training)\n","\n","  # display on test set: appends a prediction column\n","  predictions = model_NB.transform(test)\n","\n","  # diagnostic testing\n","  prela_df = predictions.select(\"prediction\",\"label\")\n","  prela_df=prela_df.withColumn(\"TP\", TP(prela_df.prediction,prela_df.label))\n","  prela_df=prela_df.withColumn(\"FP\", FP(prela_df.prediction,prela_df.label))\n","  prela_df=prela_df.withColumn(\"FN\", FN(prela_df.prediction,prela_df.label))\n","\n","  TP_ = prela_df.where(prela_df.TP==1).count()\n","  FP_ = prela_df.where(prela_df.FP==1).count()\n","  FN_ = prela_df.where(prela_df.FN==1).count()\n","\n","  precision = TP_/(TP_+FP_)\n","  recall = TP_/(TP_+FN_)\n","  F1 = 2*(precision*recall)/(precision+recall)\n","\n","  # compute accuracy of on test set: compares labelCol and predictionCol\n","  evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","  accuracy = evaluator.evaluate(predictions)\n","\n","  # return test results and model object\n","  return (accuracy,precision,recall,F1,model_NB)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dXjd_oCODA6m","executionInfo":{"status":"ok","timestamp":1618623629281,"user_tz":240,"elapsed":12746,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"b66b6a68-4919-42d3-8d47-0fd1465365c1"},"source":["\"\"\"\n","Examples\n","\"\"\"\n","acc,precision,recall,F1,modelNB = NAIVEBAYES_CV(0.2684835187532758,\"complement\")\n","print(\"Accuracy: \",acc)\n","print(\"Precision: \",precision)\n","print(\"Recall: \",recall)\n","print(\"F1 Score: \",F1)\n","print()\n","acc,precision,recall,F1,modelNB2 = NAIVEBAYES_CV(0.2684835187532758,\"multinomial\")\n","print(\"Accuracy: \",acc)\n","print(\"Precision: \",precision)\n","print(\"Recall: \",recall)\n","print(\"F1 Score: \",F1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy:  0.6130790190735694\n","Precision:  0.589041095890411\n","Recall:  0.712707182320442\n","F1 Score:  0.645\n","\n","Accuracy:  0.625748502994012\n","Precision:  0.5959595959595959\n","Recall:  0.7239263803680982\n","F1 Score:  0.6537396121883657\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OlZ7iiZMfQQp"},"source":["### Testing with different model types and random smooth value"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOJociinksMh","executionInfo":{"status":"ok","timestamp":1618624535870,"user_tz":240,"elapsed":107185,"user":{"displayName":"Sispapjen","photoUrl":"","userId":"00407414900530577219"}},"outputId":"715cc7a8-d9c0-468b-ed6e-596179ec56f9"},"source":["'''\n","Iteration tests on Naive-Bayes\n","\n","iter_total: iterations for different smoothing nb\n","iter_each: iterations for the same smoothing nb\n","'''\n","import statistics\n","\n","extract_method = \"CountVectorizer\"\n","iter_each = 10\n","iter_total = 50\n","m_types = [\"complement\", \"multinomial\"]\n","accs = []\n","f1s = []\n","for model_type in m_types:\n","  for k in range(iter_total):\n","    accuracies = []\n","    smoothing = random.uniform(0.01, 0.8)\n","    for i in range(iter_each):\n","      acc,precision,recall,F1,modelNB = NAIVEBAYES_CV(smoothing, model_type)\n","      accs.append(acc)\n","      f1s.append(F1)\n","    mean_acc = statistics.mean(accs)\n","    mean_f1 = statistics.mean(f1s)\n","    print(\"=> Mean_acc: \", mean_acc,\" => Mean_f1: \",mean_f1, \"- Smoothing:\", smoothing, \"- Model:\", model_type)\n","    means.append((mean_acc,mean_f1, smoothing, model_type, extract_method))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["=> Mean_acc:  0.6079048522164284  => Mean_f1:  0.6393361797046069 - Smoothing: 0.08412955728123993 - Model: complement\n","=> Mean_acc:  0.6064216016547912  => Mean_f1:  0.6328262146033021 - Smoothing: 0.06817815498039603 - Model: complement\n","=> Mean_acc:  0.6070998909594324  => Mean_f1:  0.6348180274709192 - Smoothing: 0.5746608805970586 - Model: complement\n","=> Mean_acc:  0.6061228937081395  => Mean_f1:  0.6364310647236601 - Smoothing: 0.6579209137657336 - Model: complement\n","=> Mean_acc:  0.6072693347031953  => Mean_f1:  0.6365346408691858 - Smoothing: 0.7500617358310381 - Model: complement\n","=> Mean_acc:  0.6042366473040159  => Mean_f1:  0.6355815049626126 - Smoothing: 0.32451570157883275 - Model: complement\n","=> Mean_acc:  0.6049446181875157  => Mean_f1:  0.636565527559283 - Smoothing: 0.3458478280482886 - Model: complement\n","=> Mean_acc:  0.6070204516748807  => Mean_f1:  0.6380786694401938 - Smoothing: 0.7567512379372225 - Model: complement\n","=> Mean_acc:  0.6065041827443748  => Mean_f1:  0.6379627189297483 - Smoothing: 0.1251577258841254 - Model: complement\n","=> Mean_acc:  0.6060777755860743  => Mean_f1:  0.635888461900677 - Smoothing: 0.7999790142773606 - Model: complement\n","=> Mean_acc:  0.6065593618405646  => Mean_f1:  0.63656347807348 - Smoothing: 0.7437480502006946 - Model: multinomial\n","=> Mean_acc:  0.6068401455862591  => Mean_f1:  0.6374557231764412 - Smoothing: 0.20363980290970343 - Model: multinomial\n","=> Mean_acc:  0.6077698359512772  => Mean_f1:  0.6387715065503345 - Smoothing: 0.4402098580607615 - Model: multinomial\n","=> Mean_acc:  0.6084796522355853  => Mean_f1:  0.6392432070426657 - Smoothing: 0.4606103363318428 - Model: multinomial\n","=> Mean_acc:  0.6088649002341316  => Mean_f1:  0.6396498056051982 - Smoothing: 0.3105906032061619 - Model: multinomial\n","=> Mean_acc:  0.6093726765715728  => Mean_f1:  0.6401121724322381 - Smoothing: 0.5520034878698404 - Model: multinomial\n","=> Mean_acc:  0.6099306089752691  => Mean_f1:  0.6410054474867944 - Smoothing: 0.4641677108046691 - Model: multinomial\n","=> Mean_acc:  0.6094586455629067  => Mean_f1:  0.6408139043252267 - Smoothing: 0.3704738931770633 - Model: multinomial\n","=> Mean_acc:  0.6092665304416476  => Mean_f1:  0.6411829088541217 - Smoothing: 0.2545666614520077 - Model: multinomial\n","=> Mean_acc:  0.6089407378127506  => Mean_f1:  0.640983560014507 - Smoothing: 0.1021135236344608 - Model: multinomial\n"],"name":"stdout"}]}]}